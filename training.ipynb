{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-21T14:26:40.187857Z",
     "start_time": "2024-11-21T14:26:39.337451Z"
    }
   },
   "source": [
    "from datasets import load_from_disk\n",
    "import torch\n",
    "import torch.nn as nn"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T14:27:46.516886Z",
     "start_time": "2024-11-21T14:27:46.514727Z"
    }
   },
   "cell_type": "code",
   "source": "import torch",
   "id": "4a97cc6fdfacef26",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T14:27:28.307774Z",
     "start_time": "2024-11-21T14:27:27.994580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3.5-MoE-instruct\", trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/Phi-3.5-MoE-instruct\", trust_remote_code=True)"
   ],
   "id": "b25a6a07f519d09e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encountered exception while importing flash_attn: No module named 'flash_attn'\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "This modeling file requires the following packages that were not found in your environment: flash_attn. Run `pip install flash_attn`",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 5\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AutoTokenizer, AutoModelForCausalLM\n\u001B[1;32m      4\u001B[0m tokenizer \u001B[38;5;241m=\u001B[39m AutoTokenizer\u001B[38;5;241m.\u001B[39mfrom_pretrained(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmicrosoft/Phi-3.5-MoE-instruct\u001B[39m\u001B[38;5;124m\"\u001B[39m, trust_remote_code\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m----> 5\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mAutoModelForCausalLM\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmicrosoft/Phi-3.5-MoE-instruct\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/pycharm/MT Final/.venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:553\u001B[0m, in \u001B[0;36m_BaseAutoModelClass.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[0m\n\u001B[1;32m    551\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_remote_code \u001B[38;5;129;01mand\u001B[39;00m trust_remote_code:\n\u001B[1;32m    552\u001B[0m     class_ref \u001B[38;5;241m=\u001B[39m config\u001B[38;5;241m.\u001B[39mauto_map[\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m]\n\u001B[0;32m--> 553\u001B[0m     model_class \u001B[38;5;241m=\u001B[39m \u001B[43mget_class_from_dynamic_module\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    554\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclass_ref\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcode_revision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcode_revision\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mhub_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    555\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    556\u001B[0m     _ \u001B[38;5;241m=\u001B[39m hub_kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcode_revision\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m    557\u001B[0m     \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mregister(config\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m, model_class, exist_ok\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/pycharm/MT Final/.venv/lib/python3.12/site-packages/transformers/dynamic_module_utils.py:540\u001B[0m, in \u001B[0;36mget_class_from_dynamic_module\u001B[0;34m(class_reference, pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, repo_type, code_revision, **kwargs)\u001B[0m\n\u001B[1;32m    538\u001B[0m     code_revision \u001B[38;5;241m=\u001B[39m revision\n\u001B[1;32m    539\u001B[0m \u001B[38;5;66;03m# And lastly we get the class inside our newly created module\u001B[39;00m\n\u001B[0;32m--> 540\u001B[0m final_module \u001B[38;5;241m=\u001B[39m \u001B[43mget_cached_module_file\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    541\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrepo_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    542\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodule_file\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m.py\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    543\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    544\u001B[0m \u001B[43m    \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    545\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresume_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    546\u001B[0m \u001B[43m    \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    547\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    548\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcode_revision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    549\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    550\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrepo_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrepo_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    551\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    552\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m get_class_in_module(class_name, final_module, force_reload\u001B[38;5;241m=\u001B[39mforce_download)\n",
      "File \u001B[0;32m~/pycharm/MT Final/.venv/lib/python3.12/site-packages/transformers/dynamic_module_utils.py:365\u001B[0m, in \u001B[0;36mget_cached_module_file\u001B[0;34m(pretrained_model_name_or_path, module_file, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, repo_type, _commit_hash, **deprecated_kwargs)\u001B[0m\n\u001B[1;32m    362\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[1;32m    364\u001B[0m \u001B[38;5;66;03m# Check we have all the requirements in our environment\u001B[39;00m\n\u001B[0;32m--> 365\u001B[0m modules_needed \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_imports\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresolved_module_file\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    367\u001B[0m \u001B[38;5;66;03m# Now we move the module inside our cached dynamic modules.\u001B[39;00m\n\u001B[1;32m    368\u001B[0m full_submodule \u001B[38;5;241m=\u001B[39m TRANSFORMERS_DYNAMIC_MODULE_NAME \u001B[38;5;241m+\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39msep \u001B[38;5;241m+\u001B[39m submodule\n",
      "File \u001B[0;32m~/pycharm/MT Final/.venv/lib/python3.12/site-packages/transformers/dynamic_module_utils.py:197\u001B[0m, in \u001B[0;36mcheck_imports\u001B[0;34m(filename)\u001B[0m\n\u001B[1;32m    194\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[1;32m    196\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(missing_packages) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 197\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\n\u001B[1;32m    198\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThis modeling file requires the following packages that were not found in your environment: \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    199\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(missing_packages)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. Run `pip install \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(missing_packages)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m`\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    200\u001B[0m     )\n\u001B[1;32m    202\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m get_relative_imports(filename)\n",
      "\u001B[0;31mImportError\u001B[0m: This modeling file requires the following packages that were not found in your environment: flash_attn. Run `pip install flash_attn`"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T09:44:18.398176Z",
     "start_time": "2024-11-20T09:44:17.289158Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import os\n",
    "\n",
    "llama_1b = AutoModelForCausalLM.from_pretrained(\"models/meta-llama/llama-3.2-1B\")\n",
    "llama_3b = AutoModelForCausalLM.from_pretrained(\"models/meta-llama/llama-3.2-3B\")\n",
    "llama_tokenizer = AutoTokenizer.from_pretrained(\"tokenizers/meta-llama/llama-3.2-1B\")"
   ],
   "id": "d66dac64d2443d88",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "db06ec8b5bb9490bb476abb180a2e32a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T09:44:20.985657Z",
     "start_time": "2024-11-20T09:44:20.962603Z"
    }
   },
   "cell_type": "code",
   "source": "wikitext2 = load_from_disk('data/wikitext-2')",
   "id": "1e3509ecebcd055a",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T09:44:21.838491Z",
     "start_time": "2024-11-20T09:44:21.803553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llama_1b_truncated = AutoModelForCausalLM.from_pretrained(\"models/meta-llama/llama-3.2-1B\")\n",
    "llama_1b_truncated.model.layers = llama_1b_truncated.model.layers[10:]"
   ],
   "id": "d974dfeb9f47360b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T09:44:22.004196Z",
     "start_time": "2024-11-20T09:44:21.999268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dims: list[int], latent_dim: int):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_dim: Dimension of input vector\n",
    "            hidden_dims: List of hidden layer dimensions\n",
    "            latent_dim: Dimension of latent space (encoded vector)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Build encoder layers\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "\n",
    "        # Add hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm1d(hidden_dim)\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "\n",
    "        # Add final layer to latent dimension\n",
    "        layers.append(nn.Linear(prev_dim, latent_dim))\n",
    "\n",
    "        self.encoder = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim: int, hidden_dims: list[int], output_dim: int):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            latent_dim: Dimension of latent space (encoded vector)\n",
    "            hidden_dims: List of hidden layer dimensions (in reverse order of encoder)\n",
    "            output_dim: Dimension of output vector\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Build decoder layers\n",
    "        layers = []\n",
    "        prev_dim = latent_dim\n",
    "\n",
    "        # Add hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm1d(hidden_dim)\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "\n",
    "        # Add final layer to output dimension\n",
    "        layers.append(nn.Linear(prev_dim, output_dim))\n",
    "\n",
    "        self.decoder = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(x)\n",
    "\n",
    "class VectorEncoderDecoder(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dims: list[int], latent_dim: int, output_dim: int):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_dim: Dimension of input vector\n",
    "            hidden_dims: List of hidden layer dimensions\n",
    "            latent_dim: Dimension of latent space (encoded vector)\n",
    "            output_dim: Dimension of output vector\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = Encoder(input_dim, hidden_dims, latent_dim)\n",
    "        self.decoder = Decoder(latent_dim, hidden_dims[::-1], output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ],
   "id": "39e867af8d3ed5fa",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T09:44:25.523052Z",
     "start_time": "2024-11-20T09:44:25.518899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class inner_translation_model(nn.Module):\n",
    "    def __init__(self, src_model, tgt_model, translation_model, tgt_layer, src_layer):\n",
    "        super().__init__()\n",
    "        tgt_model.model.layers = tgt_model.model.layers[tgt_layer:]\n",
    "\n",
    "        self.src_model = src_model\n",
    "        self.tgt_model = tgt_model\n",
    "        self.translation_model = translation_model\n",
    "        self.src_layer = src_layer\n",
    "        # freeze source, target models\n",
    "        for param in self.src_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.tgt_model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        model_outs = self.src_model(x, output_hidden_states=True)\n",
    "        model_outs_src_layer = model_outs.hidden_states[self.src_layer]\n",
    "        model_outs_src_layer = model_outs_src_layer.squeeze()\n",
    "        #model_outs_src_layer = model_outs_src_layer.permute(1,0,2)\n",
    "        print(model_outs_src_layer.shape)\n",
    "        translation_outs = self.translation_model(model_outs_src_layer)\n",
    "        translation_outs = translation_outs.unsqueeze(0)\n",
    "        logits = self.tgt_model(inputs_embeds = translation_outs, use_cache = False).logits\n",
    "        return translation_outs, logits\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "4e789ada0ea06e7a",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T09:44:26.355135Z",
     "start_time": "2024-11-20T09:44:26.328053Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ved = VectorEncoderDecoder(3072, [1024, 512], 256, 2048)\n",
    "itm = inner_translation_model(llama_3b, llama_1b, ved, 10, 18)"
   ],
   "id": "b97f1ae4ca1764d6",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T09:44:27.165495Z",
     "start_time": "2024-11-20T09:44:27.153939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "with open ('data/chunked_wikitext2/train.pkl', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n"
   ],
   "id": "5db63ede9345ab04",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T09:44:28.004159Z",
     "start_time": "2024-11-20T09:44:27.781682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "llama_tokenizer = AutoTokenizer.from_pretrained(\"tokenizers/meta-llama/llama-3.2-1B\")\n",
    "input = llama_tokenizer(train_data[0], return_tensors=\"pt\")"
   ],
   "id": "49cda78b8de36c50",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T09:44:29.744230Z",
     "start_time": "2024-11-20T09:44:29.741445Z"
    }
   },
   "cell_type": "code",
   "source": "print(input[\"input_ids\"].shape)",
   "id": "bfd0baeec23d56cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4446])\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T09:45:17.466330Z",
     "start_time": "2024-11-20T09:44:30.863424Z"
    }
   },
   "cell_type": "code",
   "source": "out = itm(input[\"input_ids\"])",
   "id": "cef8a1d72c04707a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4446, 3072])\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T09:45:26.439428Z",
     "start_time": "2024-11-20T09:45:26.436514Z"
    }
   },
   "cell_type": "code",
   "source": "out[0].shape",
   "id": "a62903cd1b35eebf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4446, 2048])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T09:45:27.386733Z",
     "start_time": "2024-11-20T09:45:27.385178Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "c233f615fabf3b82",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T09:52:15.348036Z",
     "start_time": "2024-11-20T09:52:15.345130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def loss_fn(intermediate_pred, intermediate_tgt, logits_pred, logits_tgt):\n",
    "    cosine_loss = nn.CosineEmbeddingLoss()\n",
    "    cosine_loss_out = cosine_loss(\n",
    "        intermediate_pred.squeeze(),\n",
    "        intermediate_tgt.squeeze(),\n",
    "        torch.ones(intermediate_pred.shape[1]).to(device)\n",
    "    )\n",
    "\n",
    "    kl_div = nn.KLDivLoss()\n",
    "    kl_div_out = kl_div(\n",
    "        logits_pred.log_softmax(dim=-1),\n",
    "        logits_tgt.softmax(dim=-1)\n",
    "    )\n",
    "    return cosine_loss_out + kl_div_out\n",
    "\n"
   ],
   "id": "f443374aa3a831f7",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T09:45:29.195110Z",
     "start_time": "2024-11-20T09:45:28.967648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(itm.parameters(), lr=0.001)\n",
    "device = \"mps\"\n",
    "epochs = 2"
   ],
   "id": "edf12a533ffb4b5",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T09:45:37.139464Z",
     "start_time": "2024-11-20T09:45:29.750284Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llama_1b = AutoModelForCausalLM.from_pretrained(\"models/meta-llama/llama-3.2-1B\")\n",
    "llama_1b.to(device)\n",
    "itm.to(device)"
   ],
   "id": "78cec11386709d03",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inner_translation_model(\n",
       "  (src_model): LlamaForCausalLM(\n",
       "    (model): LlamaModel(\n",
       "      (embed_tokens): Embedding(128256, 3072)\n",
       "      (layers): ModuleList(\n",
       "        (0-27): 28 x LlamaDecoderLayer(\n",
       "          (self_attn): LlamaSdpaAttention(\n",
       "            (q_proj): Linear(in_features=3072, out_features=3072, bias=False)\n",
       "            (k_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "            (o_proj): Linear(in_features=3072, out_features=3072, bias=False)\n",
       "            (rotary_emb): LlamaRotaryEmbedding()\n",
       "          )\n",
       "          (mlp): LlamaMLP(\n",
       "            (gate_proj): Linear(in_features=3072, out_features=8192, bias=False)\n",
       "            (up_proj): Linear(in_features=3072, out_features=8192, bias=False)\n",
       "            (down_proj): Linear(in_features=8192, out_features=3072, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "          (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "        )\n",
       "      )\n",
       "      (norm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "      (rotary_emb): LlamaRotaryEmbedding()\n",
       "    )\n",
       "    (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n",
       "  )\n",
       "  (tgt_model): LlamaForCausalLM(\n",
       "    (model): LlamaModel(\n",
       "      (embed_tokens): Embedding(128256, 2048)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x LlamaDecoderLayer(\n",
       "          (self_attn): LlamaSdpaAttention(\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "            (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (rotary_emb): LlamaRotaryEmbedding()\n",
       "          )\n",
       "          (mlp): LlamaMLP(\n",
       "            (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "            (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "            (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "          (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        )\n",
       "      )\n",
       "      (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      (rotary_emb): LlamaRotaryEmbedding()\n",
       "    )\n",
       "    (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
       "  )\n",
       "  (translation_model): VectorEncoderDecoder(\n",
       "    (encoder): Encoder(\n",
       "      (encoder): Sequential(\n",
       "        (0): Linear(in_features=3072, out_features=1024, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): Linear(in_features=1024, out_features=512, bias=True)\n",
       "        (4): ReLU()\n",
       "        (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): Linear(in_features=512, out_features=256, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (decoder): Decoder(\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): Linear(in_features=512, out_features=1024, bias=True)\n",
       "        (4): ReLU()\n",
       "        (5): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T10:39:13.707466Z",
     "start_time": "2024-11-20T10:04:54.849800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "max_len = 1000\n",
    "loss_sum = 0\n",
    "for epoch in range(epochs):\n",
    "    for i, text in enumerate(train_data):\n",
    "        input = llama_tokenizer(text, max_length=max_len, return_tensors=\"pt\", truncation=True)\n",
    "\n",
    "        #input = llama_tokenizer(text, return_tensors=\"pt\")\n",
    "        input.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        intermediate_pred, logits_pred = itm(input[\"input_ids\"])\n",
    "        true_out = llama_1b(input[\"input_ids\"], output_hidden_states=True)\n",
    "        intermediate_tgt = true_out.hidden_states[10]\n",
    "        logits_tgt = true_out.logits\n",
    "        loss = loss_fn(intermediate_pred, intermediate_tgt, logits_pred, logits_tgt)\n",
    "        loss_sum += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Epoch: {epoch}, Loss: {loss_sum / 10}\")\n",
    "            loss_sum = 0"
   ],
   "id": "971a95d5be3a1bba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 3072])\n",
      "Epoch: 0, Loss: 0.0358019083738327\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([833, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([13, 3072])\n",
      "torch.Size([13, 3072])\n",
      "torch.Size([33, 3072])\n",
      "torch.Size([18, 3072])\n",
      "torch.Size([12, 3072])\n",
      "Epoch: 0, Loss: 0.3406906008720398\n",
      "torch.Size([27, 3072])\n",
      "torch.Size([573, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([782, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "Epoch: 0, Loss: 0.3396680772304535\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "Epoch: 0, Loss: 0.33113611936569215\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "Epoch: 0, Loss: 0.2996467649936676\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "Epoch: 0, Loss: 0.2920100539922714\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "Epoch: 0, Loss: 0.30436004102230074\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([803, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "Epoch: 0, Loss: 0.28864108920097353\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([911, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([880, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "Epoch: 0, Loss: 0.29215253293514254\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([749, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "Epoch: 0, Loss: 0.27065703868865965\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "Epoch: 0, Loss: 0.2911975622177124\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "Epoch: 0, Loss: 0.28100327849388124\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([840, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "Epoch: 0, Loss: 0.27726792693138125\n",
      "torch.Size([474, 3072])\n",
      "torch.Size([353, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([57, 3072])\n",
      "Epoch: 0, Loss: 0.2948164463043213\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([738, 3072])\n",
      "torch.Size([1000, 3072])\n",
      "torch.Size([610, 3072])\n",
      "torch.Size([1000, 3072])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 36.92 GB, other allocations: 23.83 GB, max allowed: 61.20 GB). Tried to allocate 489.26 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[30], line 17\u001B[0m\n\u001B[1;32m     14\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_fn(intermediate_pred, intermediate_tgt, logits_pred, logits_tgt)\n\u001B[1;32m     15\u001B[0m loss_sum \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n\u001B[0;32m---> 17\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m10\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/pycharm/MT Final/.venv/lib/python3.12/site-packages/torch/_tensor.py:581\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    571\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    572\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    573\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    574\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    579\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    580\u001B[0m     )\n\u001B[0;32m--> 581\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    582\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    583\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/pycharm/MT Final/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    342\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    344\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    345\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    346\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 347\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    348\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    349\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    350\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    351\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    352\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    353\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    354\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    355\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/pycharm/MT Final/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[0;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[1;32m    823\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[1;32m    824\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 825\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    826\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    827\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[1;32m    828\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    829\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[0;31mRuntimeError\u001B[0m: MPS backend out of memory (MPS allocated: 36.92 GB, other allocations: 23.83 GB, max allowed: 61.20 GB). Tried to allocate 489.26 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T11:06:14.564582Z",
     "start_time": "2024-11-20T11:06:14.332525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "translator = itm.translation_model\n",
    "torch.save(translator, 'models/translator_later.pth')"
   ],
   "id": "f10991339e0b5f8e",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b46f3bd528f0eee0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
