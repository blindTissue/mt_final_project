{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T01:13:33.525637Z",
     "start_time": "2024-12-07T01:13:33.011244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "def load_data(max_length=512):\n",
    "    print(\"Loading dataset from HuggingFace...\")\n",
    "    dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n",
    "    test_texts = dataset['test']['text']\n",
    "\n",
    "    filtered_texts = [text for text in test_texts if text.strip() and len(text.split()) <= max_length and len(text.split()) > 50]\n",
    "    print(f\"Processed {len(filtered_texts)} samples after filtering\")\n",
    "\n",
    "    return filtered_texts"
   ],
   "id": "5da844767c3e7f9f",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T01:13:35.207193Z",
     "start_time": "2024-12-07T01:13:33.530172Z"
    }
   },
   "cell_type": "code",
   "source": "filtered_data = load_data()",
   "id": "3e9a82793456197b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from HuggingFace...\n",
      "Processed 1626 samples after filtering\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T01:13:35.280199Z",
     "start_time": "2024-12-07T01:13:35.277680Z"
    }
   },
   "cell_type": "code",
   "source": "filtered_data[0]",
   "id": "50d73d2ff2a64d63",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Robert Boulter is an English film , television and theatre actor . He had a guest @-@ starring role on the television series The Bill in 2000 . This was followed by a starring role in the play Herons written by Simon Stephens , which was performed in 2001 at the Royal Court Theatre . He had a guest role in the television series Judge John Deed in 2002 . In 2004 Boulter landed a role as \" Craig \" in the episode \" Teddy \\'s Story \" of the television series The Long Firm ; he starred alongside actors Mark Strong and Derek Jacobi . He was cast in the 2005 theatre productions of the Philip Ridley play Mercury Fur , which was performed at the Drum Theatre in Plymouth and the Menier Chocolate Factory in London . He was directed by John Tiffany and starred alongside Ben Whishaw , Shane Zaza , Harry Kent , Fraser Ayres , Sophie Stanton and Dominic Hall . \\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T01:13:45.645664Z",
     "start_time": "2024-12-07T01:13:35.284445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "llama_1b = AutoModelForCausalLM.from_pretrained('models/meta-llama/llama-3.2-1B').to('mps')\n",
    "llama_3b = AutoModelForCausalLM.from_pretrained('models/meta-llama/llama-3.2-3B').to('mps')"
   ],
   "id": "4b0f91ab15263f8e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d2e4a656d5bb41f789a5fa9d7ff01a7b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T01:13:45.651594Z",
     "start_time": "2024-12-07T01:13:45.650277Z"
    }
   },
   "cell_type": "code",
   "source": "device = 'mps'",
   "id": "1496836593949883",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T01:13:45.657902Z",
     "start_time": "2024-12-07T01:13:45.655319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "class LlamaIntermediateLayerExtractor:\n",
    "    def __init__(self, model_3b_path):\n",
    "        \"\"\"\n",
    "        Initialize extractor for Llama 3.2 1b and 3b models\n",
    "\n",
    "        Args:\n",
    "            model_1b_path (str): Path or HuggingFace model ID for 1b model\n",
    "            model_3b_path (str): Path or HuggingFace model ID for 3b model\n",
    "        \"\"\"\n",
    "        # Load models and tokenizers\n",
    "        self.model_3b = AutoModelForCausalLM.from_pretrained(model_3b_path).to(device)\n",
    "\n",
    "        self.tokenizer_1b = AutoTokenizer.from_pretrained(\"tokenizers/meta-llama/llama-3.2-1B\")\n",
    "        self.tokenizer_3b = AutoTokenizer.from_pretrained(\"tokenizers/meta-llama/llama-3.2-3B\")\n",
    "\n",
    "        self.model_3b.eval()\n",
    "\n",
    "        # Hooks to capture intermediate layer outputs\n",
    "        self.intermediate_output_3b = None\n",
    "\n",
    "\n",
    "    def _register_3b_hook(self):\n",
    "        \"\"\"Register hook for 3b model's 18th layer\"\"\"\n",
    "        def hook(module, input, output):\n",
    "            self.intermediate_output_3b = output[0]\n",
    "\n",
    "        # Adjust this path based on your specific model structure\n",
    "        target_layer = self.model_3b.model.layers[17]  # 0-indexed, so 18th layer is index 17\n",
    "        self.hook_3b = target_layer.register_forward_hook(hook)\n",
    "\n",
    "    def extract_intermediate_representations(self, text_chunks, max_length=512):\n",
    "        \"\"\"\n",
    "        Extract intermediate representations for given text chunks\n",
    "\n",
    "        Args:\n",
    "            text_chunks (list): List of text chunks to process\n",
    "            max_length (int): Maximum token length to process\n",
    "\n",
    "        Returns:\n",
    "            tuple: (intermediate representations for 1b, intermediate representations for 3b)\n",
    "        \"\"\"\n",
    "        # Reset intermediate outputs\n",
    "        self.intermediate_output_3b = None\n",
    "\n",
    "        self._register_3b_hook()\n",
    "\n",
    "        repr_3b_list = []\n",
    "\n",
    "        try:\n",
    "            for chunk in text_chunks:\n",
    "\n",
    "                # Tokenize and process 3b model\n",
    "                inputs_3b = self.tokenizer_3b(\n",
    "                    chunk,\n",
    "                    return_tensors='pt',\n",
    "                    truncation=True,\n",
    "                    max_length=max_length\n",
    "                ).to(device)\n",
    "\n",
    "                # Forward pass to trigger hooks\n",
    "                with torch.no_grad():\n",
    "                    _ = self.model_3b(**inputs_3b)\n",
    "\n",
    "\n",
    "                if self.intermediate_output_3b is not None:\n",
    "                    repr_3b_list.append(self.intermediate_output_3b.detach())\n",
    "\n",
    "        finally:\n",
    "            self.hook_3b.remove()\n",
    "\n",
    "        return repr_3b_list\n",
    "\n"
   ],
   "id": "8719017dd445a7d8",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T01:13:50.639012Z",
     "start_time": "2024-12-07T01:13:45.662109Z"
    }
   },
   "cell_type": "code",
   "source": "extractor = LlamaIntermediateLayerExtractor('models/meta-llama/llama-3.2-3B')",
   "id": "fe7619c114374f2c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dbededcdfe85446cba431b0167a393da"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T01:13:50.684989Z",
     "start_time": "2024-12-07T01:13:50.643779Z"
    }
   },
   "cell_type": "code",
   "source": "llama_1b_trunc = AutoModelForCausalLM.from_pretrained('models/meta-llama/llama-3.2-1B')",
   "id": "ddf816d3e93fc44a",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T01:13:50.691005Z",
     "start_time": "2024-12-07T01:13:50.689459Z"
    }
   },
   "cell_type": "code",
   "source": "llama_1b_trunc.model.layers = llama_1b_trunc.model.layers[10:]",
   "id": "589a74ab19cbbd4e",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T01:13:55.063608Z",
     "start_time": "2024-12-07T01:13:50.695377Z"
    }
   },
   "cell_type": "code",
   "source": "llama_1b_trunc.to(device)",
   "id": "56fd8f308275608a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T01:13:55.077067Z",
     "start_time": "2024-12-07T01:13:55.073643Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Seq2SeqEncoder(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int, num_layers: int):\n",
    "        \"\"\"\n",
    "        Encoder for seq2seq model.\n",
    "        Args:\n",
    "            input_dim: Dimensionality of input vectors\n",
    "            hidden_dim: Hidden state size of the LSTM\n",
    "            num_layers: Number of LSTM layers\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input tensor of shape (batch_size, seq_len, input_dim)\n",
    "        Returns:\n",
    "            encoder_outputs: Outputs for each time step (batch_size, seq_len, hidden_dim)\n",
    "            hidden: Tuple of (h_n, c_n) (last hidden and cell states)\n",
    "        \"\"\"\n",
    "        encoder_outputs, hidden = self.lstm(x)\n",
    "        return encoder_outputs, hidden\n",
    "\n",
    "\n",
    "class Seq2SeqDecoder(nn.Module):\n",
    "    def __init__(self, hidden_dim: int, output_dim: int, num_layers: int):\n",
    "        \"\"\"\n",
    "        Decoder for seq2seq model.\n",
    "        Args:\n",
    "            hidden_dim: Dimensionality of the encoded hidden state\n",
    "            output_dim: Dimensionality of output vectors (same as input_dim)\n",
    "            num_layers: Number of LSTM layers (should match encoder)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(hidden_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input tensor to the decoder (batch_size, seq_len, hidden_dim)\n",
    "            hidden: Tuple of (h_n, c_n) from the encoder\n",
    "        Returns:\n",
    "            outputs: Decoded sequence (batch_size, seq_len, output_dim)\n",
    "        \"\"\"\n",
    "        lstm_out, hidden = self.lstm(x, hidden)\n",
    "        outputs = self.fc(lstm_out)\n",
    "        return outputs, hidden\n",
    "\n",
    "\n",
    "class Seq2SeqModel(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int, output_dim: int, num_layers: int):\n",
    "        \"\"\"\n",
    "        Combines encoder and decoder into a seq2seq model.\n",
    "        Args:\n",
    "            input_dim: Dimensionality of input vectors\n",
    "            hidden_dim: Hidden state size\n",
    "            num_layers: Number of LSTM layers\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.encoder = Seq2SeqEncoder(input_dim, hidden_dim, num_layers)\n",
    "        self.decoder = Seq2SeqDecoder(hidden_dim, output_dim, num_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input sequence of shape (batch_size, seq_len, input_dim)\n",
    "        Returns:\n",
    "            output: Reconstructed sequence of shape (batch_size, seq_len, input_dim)\n",
    "        \"\"\"\n",
    "        # Encoder\n",
    "        encoder_outputs, hidden = self.encoder(x)\n",
    "\n",
    "        # Decoder (Use encoder outputs as initial input)\n",
    "        output, _ = self.decoder(encoder_outputs, hidden)\n",
    "        return output"
   ],
   "id": "aa62d0cb5983279c",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T01:13:55.090474Z",
     "start_time": "2024-12-07T01:13:55.087295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TransformerEmbedder(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, layers):\n",
    "        super(TransformerEmbedder, self).__init__()\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=input_dim, nhead=8, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=layers)\n",
    "        self.activation = nn.GELU()\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mask = nn.Transformer().generate_square_subsequent_mask(x.shape[1])\n",
    "        #print(mask.shape)\n",
    "        x = self.transformer_encoder(x, mask=mask, is_causal=True)\n",
    "        x = self.activation(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ],
   "id": "c5a445b958a7fff8",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T01:13:55.098162Z",
     "start_time": "2024-12-07T01:13:55.096378Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class denseModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(denseModel, self).__init__()\n",
    "        layers = [\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        ]\n",
    "        self.model = nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n"
   ],
   "id": "6fe059dbca8630d6",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T01:12:26.332958Z",
     "start_time": "2024-12-07T01:12:26.256955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#seq2seqmodel_cos_1000 = torch.load('seq2seqmodel_1000_cosine.pth', weights_only=False)\n",
    "#seq2seqmodel_1000 = torch.load('seq2seqmodel_1000.pth', weights_only=False)\n",
    "#transformer1000 = torch.load('transformer_embedder_1000.pth', weights_only=False)\n",
    "simple_encoder_cosine = torch.load('simple_encoder_decoder_3_layers_cosine.pth', weights_only=False).to(device)"
   ],
   "id": "c7afec08efb4e86b",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T01:12:27.534125Z",
     "start_time": "2024-12-07T01:12:27.301011Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer = AutoTokenizer.from_pretrained('tokenizers/meta-llama/llama-3.2-1B')",
   "id": "4d0ee1c1c9237d2a",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T01:12:28.754352Z",
     "start_time": "2024-12-07T01:12:28.752045Z"
    }
   },
   "cell_type": "code",
   "source": "from tqdm import tqdm",
   "id": "70c6984c48012c35",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T00:54:26.144646Z",
     "start_time": "2024-12-07T00:54:26.110261Z"
    }
   },
   "cell_type": "code",
   "source": "simple_encoder_cosine = torch.load('simple_encoder_decoder_3_layers.pth', weights_only=False)",
   "id": "fdc395829f1a6ab5",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T01:13:22.379015Z",
     "start_time": "2024-12-07T01:13:18.233293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results = {\n",
    "    'original': [],\n",
    "    'llama_3_1': [],\n",
    "    'dense_cosine': [],\n",
    "    'llama_3_3': []\n",
    "}\n",
    "for text in tqdm(filtered_data[:100]):\n",
    "    results['original'].append(text)\n",
    "    with torch.no_grad():\n",
    "        logits = llama_1b(input_ids = tokenizer.encode(text, return_tensors='pt').to(device)).logits\n",
    "        output = tokenizer.decode(torch.argmax(logits, -1).squeeze())\n",
    "        results['llama_3_1'].append(output)\n",
    "        logits = llama_3b(input_ids = tokenizer.encode(text, return_tensors='pt').to(device)).logits\n",
    "        output = tokenizer.decode(torch.argmax(logits, -1).squeeze())\n",
    "        results['llama_3_3'].append(output)\n",
    "        intermediate = extractor.extract_intermediate_representations([text])\n",
    "        projected = simple_encoder_cosine(intermediate[0])\n",
    "        output = llama_1b_trunc(inputs_embeds = projected)\n",
    "        results['dense_cosine'].append(tokenizer.decode(torch.argmax(output.logits, -1).squeeze()))\n",
    "        break\n",
    "\n",
    "\n"
   ],
   "id": "e5aa4b086373c8f6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:04<?, ?it/s]\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T00:54:33.116508Z",
     "start_time": "2024-12-07T00:54:31.438765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sentences = [results['original'][0], results['llama_3_1'][0], results['dense_cosine'][0], results['llama_3_3'][0]]\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings)\n"
   ],
   "id": "de4c59dff2348cb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00477041 -0.02355691  0.0128001  ...  0.00318041 -0.01829152\n",
      "  -0.00857943]\n",
      " [ 0.02149017  0.02279039  0.01305025 ...  0.0407836  -0.0451827\n",
      "  -0.01794937]\n",
      " [ 0.01343295 -0.05770705  0.01454598 ...  0.03309499 -0.02617651\n",
      "  -0.01864703]\n",
      " [ 0.02346542  0.00675755  0.01517578 ...  0.05409851 -0.03955113\n",
      "  -0.01145439]]\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T01:03:48.995738Z",
     "start_time": "2024-12-07T01:03:48.993093Z"
    }
   },
   "cell_type": "code",
   "source": "results['llama_3_1'][1]",
   "id": "9d855b37f9210d57",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Question the2009, the.ton was in heredaw in the film The, by David Ravenhill. The also in stage number2007 episode of the BBC series The The, as by a  in the 2007 film production of The to S a by Davidie Rourke. In to Curse was a at the Theatre, London West Borough of Hammersmith and Fulham. Inoulter appeared in the episodes in 2007, includingbreak Robbery and director David Barclesi and and the\\'t Punch by by Davidly Blackburn. In  2008, Boulter appeared his guest appearance on the -part episode episode episode of of the BBC series,aking the Dead. playing by a appearance in the  series,ivors in  2008. In appeared a role role in the episodes of the television series Thety in 2000. and well Drieran \" \". Inoulter appeared in the 2011 film Thei, by David Leonti, InIn'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ],
   "id": "e059225c213855e0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T01:11:34.100292Z",
     "start_time": "2024-12-07T01:11:27.676411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llama_to_llama_sim = []\n",
    "llama_to_dense_sim = []\n",
    "for i in tqdm(range(100)):\n",
    "    llama_3_1_embedding = model.encode([results['llama_3_1'][i]])\n",
    "    dense_cosine_embedding = model.encode([results['dense_cosine'][i]])\n",
    "    llama_3_3_embedding = model.encode([results['llama_3_3'][i]])\n",
    "    llama_to_llama_sim.append(cosine_similarity(llama_3_1_embedding, llama_3_3_embedding))\n",
    "    llama_to_dense_sim.append(cosine_similarity(llama_3_1_embedding, dense_cosine_embedding))\n"
   ],
   "id": "894f8b19d9b60e58",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:06<00:00, 15.57it/s]\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T01:11:35.564101Z",
     "start_time": "2024-12-07T01:11:35.562402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(np.mean(llama_to_llama_sim))\n",
    "print(np.mean(llama_to_dense_sim))"
   ],
   "id": "6d8784c03a368160",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84712243\n",
      "0.81373733\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T00:54:33.913690Z",
     "start_time": "2024-12-07T00:54:33.911002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "print(cosine_similarity(np.array([embeddings[1]]), np.array([embeddings[2]])))\n",
    "print(cosine_similarity(np.array([embeddings[1]]), np.array([embeddings[3]])))"
   ],
   "id": "6d31276849eebc82",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.77080214]]\n",
      "[[0.9091305]]\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T22:36:20.817403Z",
     "start_time": "2024-12-06T21:55:06.761957Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results = {\n",
    "    'original': [],\n",
    "    'llama_3_1': [],\n",
    "    'llama_3_3_to_1_seq2seqcosine': [],\n",
    "    'llama_3_3_to_1_seq2seq': [],\n",
    "    'llama_3_3_to_1_transformer': []\n",
    "}\n",
    "for text in tqdm(filtered_data):\n",
    "    results['original'].append(text)\n",
    "    with torch.no_grad():\n",
    "        logits = llama_1b(input_ids = tokenizer.encode(text, return_tensors='pt').to(device)).logits\n",
    "        output = tokenizer.decode(torch.argmax(logits, -1).squeeze())\n",
    "        results['llama_3_1'].append(output)\n",
    "        intermediate = extractor.extract_intermediate_representations([text])\n",
    "\n",
    "        projected_seq2seq_cosine = seq2seqmodel_cos_1000(intermediate[0])\n",
    "        projected_seq2seq = seq2seqmodel_1000(intermediate[0])\n",
    "        projected_transformer = transformer1000(intermediate[0])\n",
    "\n",
    "        logits_seq2seq_cosine = llama_1b_trunc(inputs_embeds = projected_seq2seq_cosine).logits\n",
    "        logits_seq2seq = llama_1b_trunc(inputs_embeds = projected_seq2seq).logits\n",
    "        logits_transformer = llama_1b_trunc(inputs_embeds = projected_transformer).logits\n",
    "\n",
    "        output_seq2seq_cosine = tokenizer.decode(torch.argmax(logits_seq2seq_cosine, -1).squeeze())\n",
    "        output_seq2seq = tokenizer.decode(torch.argmax(logits_seq2seq, -1).squeeze())\n",
    "        output_transformer = tokenizer.decode(torch.argmax(logits_transformer, -1).squeeze())\n",
    "\n",
    "        results['llama_3_3_to_1_seq2seqcosine'].append(output_seq2seq_cosine)\n",
    "        results['llama_3_3_to_1_seq2seq'].append(output_seq2seq)\n",
    "        results['llama_3_3_to_1_transformer'].append(output_transformer)\n",
    "\n",
    "\n"
   ],
   "id": "1613cd7e6e09a9ef",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1626/1626 [41:14<00:00,  1.52s/it]  \n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T22:38:10.814094Z",
     "start_time": "2024-12-06T22:38:10.679052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "with open(\"seq2seq_results.json\", \"w\") as f:\n",
    "    json.dump(results, f)"
   ],
   "id": "217125242f368cc6",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T22:47:36.757595Z",
     "start_time": "2024-12-06T22:47:36.740254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "with open(\"seq2seq_results.json\", \"r\") as f:\n",
    "    results = json.load(f)"
   ],
   "id": "d41638459d9a8f43",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T22:45:20.461278Z",
     "start_time": "2024-12-06T22:45:20.389353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "random_item = 1000\n",
    "print(results['original'][random_item])\n",
    "print(results['llama_3_1'][random_item])\n",
    "print(results['llama_3_3_to_1_seq2seqcosine'][random_item])\n",
    "print(results['llama_3_3_to_1_seq2seq'][random_item])\n",
    "print(results['llama_3_3_to_1_transformer'][random_item])"
   ],
   "id": "a52b80cc9c325f22",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m random_item \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1000\u001B[39m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mresults\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124moriginal\u001B[39m\u001B[38;5;124m'\u001B[39m][random_item])\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(results[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mllama_3_1\u001B[39m\u001B[38;5;124m'\u001B[39m][random_item])\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(results[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mllama_3_3_to_1_seq2seqcosine\u001B[39m\u001B[38;5;124m'\u001B[39m][random_item])\n",
      "\u001B[0;31mNameError\u001B[0m: name 'results' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T11:37:14.901358Z",
     "start_time": "2024-12-06T11:37:14.899292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleEncoderDecoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(SimpleEncoderDecoder, self).__init__()\n",
    "        self.encoder = nn.Linear(input_dim, hidden_dim)\n",
    "        self.decoder = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ],
   "id": "f632448345d1236a",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T11:37:15.817902Z",
     "start_time": "2024-12-06T11:37:15.658345Z"
    }
   },
   "cell_type": "code",
   "source": "encoder_decoder = torch.load('encoder_decoder_3b_1b_1000.pth', weights_only=False)",
   "id": "b487a8e72546744",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T11:37:22.794488Z",
     "start_time": "2024-12-06T11:37:22.710775Z"
    }
   },
   "cell_type": "code",
   "source": "projected = encoder_decoder(a[0])",
   "id": "a2fe91662ed8cf54",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T11:37:27.729933Z",
     "start_time": "2024-12-06T11:37:27.726884Z"
    }
   },
   "cell_type": "code",
   "source": "projected.shape",
   "id": "9f1d0e55cf42873f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 193, 2048])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T11:37:34.406519Z",
     "start_time": "2024-12-06T11:37:34.357436Z"
    }
   },
   "cell_type": "code",
   "source": "projected",
   "id": "fcf875c2664753c2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8522, -0.9071,  0.3003,  ...,  1.7527,  1.0636,  0.2268],\n",
       "         [-0.0397,  0.0355,  0.1739,  ..., -0.0112, -0.1490, -0.0518],\n",
       "         [-0.0396, -0.0071,  0.3657,  ..., -0.0252, -0.0199, -0.0686],\n",
       "         ...,\n",
       "         [-0.0035, -0.0020,  0.1780,  ..., -0.0967,  0.0351, -0.0145],\n",
       "         [ 0.0417,  0.0149,  0.0511,  ..., -0.0183, -0.0489, -0.0158],\n",
       "         [ 0.0794, -0.0185, -0.0200,  ...,  0.0145,  0.0353, -0.0233]]],\n",
       "       device='mps:0', grad_fn=<LinearBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T11:37:35.226122Z",
     "start_time": "2024-12-06T11:37:35.194112Z"
    }
   },
   "cell_type": "code",
   "source": "output = llama_1b_trunc(inputs_embeds = projected)",
   "id": "41d41595554cbcf4",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T11:37:38.090049Z",
     "start_time": "2024-12-06T11:37:38.088112Z"
    }
   },
   "cell_type": "code",
   "source": "output.logits.shape",
   "id": "3c3fd2b35019bf84",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 193, 128256])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T11:37:40.030855Z",
     "start_time": "2024-12-06T11:37:40.026409Z"
    }
   },
   "cell_type": "code",
   "source": "torch.argmax(output.logits, -1).shape",
   "id": "bcd83817d08fdf86",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 193])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T11:37:41.136841Z",
     "start_time": "2024-12-06T11:37:40.830706Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer = AutoTokenizer.from_pretrained('tokenizers/meta-llama/llama-3.2-1B')",
   "id": "d4a621aced0ef77f",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T11:37:45.932663Z",
     "start_time": "2024-12-06T11:37:45.901441Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.decode(torch.argmax(output.logits, -1).squeeze())",
   "id": "1228c2e7cfbbcb0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Question and.man\\n a former musician producer and artist singer artist. He is been number appearance worktour- role on the  series The New. 2006. He was the in a solo role on the album Theland. by the H. which was released in 2006. the band Society.. He has a solo appearance on the  series The John Steeleering, 2009. He 2009,@200 was a solo in the the\\'in the film, The\\'ss \" \" of the film series The Rolling Walk. he also the the and St and Steve Fey. In also also in the film2009 album album of the album and album The.. which was released in the Royal video in . the\\'s magazine.. . In also also by the D, was the the andiganam. and andey, and De, and.er, and and, Steve L. HeIn'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "5ee81ef117295b5b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T11:36:44.134930Z",
     "start_time": "2024-12-06T10:41:11.649738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenized_q = tokenizer(input, return_tensors='pt')\n",
    "out = llama_1b(**tokenized_q)"
   ],
   "id": "dc123721758eae7d",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T11:36:44.135564Z",
     "start_time": "2024-12-06T10:41:17.258330Z"
    }
   },
   "cell_type": "code",
   "source": "out.logits.shape",
   "id": "62f33a970c2ac2fc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 193, 128256])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T11:36:44.135740Z",
     "start_time": "2024-12-06T10:41:17.895492Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.decode(torch.argmax(out.logits, -1).squeeze())",
   "id": "37a059ce5851e486",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Question E.ton\\n a American actor and television and theatre actor. He is a long role rolerole role role in the BBC series The Bill in 1980. He was his by a role role in the  Theod in by David Gray. which was performed at the2001 at the Royal Court Theatre in He has a guest role in the television series The John Deed in 2002. He 2003 heoulter played a role in the Mr \" in the television \" The Bears Day \" of the television series The Bill Firm. this also in the such Strong, James Jacobi. In also also as the role2005 film production of The play Ridley play The Fur and and was performed at the Royal Theatre in London, at Royalier Chocolate Factory in London. In played cast by the Tiffany. starred alongside actors Milesishaw, David Richieaza and and Lloyd and and Jamesres and and Thompson, David Row. HeRobert'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T11:36:44.141831Z",
     "start_time": "2024-12-06T10:41:18.553851Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "a72819ed4cb89aa0",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
